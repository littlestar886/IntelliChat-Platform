import sys
from pathlib import Path
import shutil

project_root = str(Path(__file__).parent.parent.absolute())
sys.path.append(project_root)

import os
import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from utils.Classifier.classifier import TextClassifier
from utils.Classifier.data_utils import DataAugmenter
from utils.Retriever.retriever import create_rag_retriever
from dataset import questions, labels

app = Flask(__name__)

CORS(app, resources={
    r"/api/*": {
        "origins": "*",  # åªå…è®¸å‰ç«¯åœ°å€
        "methods": ["GET", "POST", "OPTIONS", "DELETE"],
        "allow_headers": ["Content-Type"],
        "supports_credentials": True,  # å…³é”®ï¼å…è®¸æºå¸¦ Cookie
    }
})

# å­˜å‚¨å¯¹è¯å†å²çš„å…¨å±€å˜é‡
chat_history = []

# ç¡®ä¿ä¸Šä¼ æ–‡ä»¶å¤¹å­˜åœ¨
UPLOAD_FOLDER = 'uploads'
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER


def init_model():
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).parent.parent
    
    # è®¾ç½®æ¨¡å‹è·¯å¾„
    models_dir = project_root / "utils" / "Classifier" / "models"
    base_model_path = models_dir / "bert-base-chinese"
    trained_model_path = models_dir / "trained_model"
    
    # ç¡®ä¿modelsç›®å½•å­˜åœ¨
    models_dir.mkdir(parents=True, exist_ok=True)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    if trained_model_path.exists():
        # éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯å¦å®Œæ•´
        required_files = ['config.json', 'model.safetensors', 'vocab.txt']
        if all((trained_model_path / f).exists() for f in required_files):
            print("âœ… åŠ è½½å·²è®­ç»ƒå¥½çš„æ¨¡å‹")
            classifier = TextClassifier(model_path=str(trained_model_path), num_labels=2)
            if classifier.load_model():
                print("âœ… æˆåŠŸåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹")
            else:
                print("âŒ è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•é‡æ–°è®­ç»ƒ...")
                return init_model()  # é€’å½’è°ƒç”¨é‡æ–°åˆå§‹åŒ–
        else:
            print("âŒ è®­ç»ƒå¥½çš„æ¨¡å‹ä¸å®Œæ•´ï¼Œé‡æ–°è®­ç»ƒ...")
            shutil.rmtree(trained_model_path, ignore_errors=True)
            return init_model()
    else:
        # é¦–æ¬¡è¿è¡Œï¼ŒåŠ è½½åŸºç¡€æ¨¡å‹
        print("ğŸ”„ é¦–æ¬¡è¿è¡Œï¼ŒåŠ è½½åŸºç¡€BERTæ¨¡å‹å¹¶è®­ç»ƒ...")
        if not base_model_path.exists():
            print(f"âŒ åŸºç¡€æ¨¡å‹ä¸å­˜åœ¨äº {base_model_path}")
            return None, None
            
        classifier = TextClassifier(model_path=str(base_model_path), num_labels=2)
        if not classifier.load_model():
            return None, None
        
        # è¿›è¡Œè®­ç»ƒ
        print("ğŸ”§ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        augmenter = DataAugmenter()
        if not classifier.train(questions, labels, batch_size=4, epochs=5, augmenter=augmenter):
            return None, None
        
        # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
        print("ğŸ’¾ ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹...")
        os.makedirs(trained_model_path, exist_ok=True)
        classifier.save_model(save_path=str(trained_model_path))
        
        # éªŒè¯ä¿å­˜ç»“æœ
        if not all((trained_model_path / f).exists() for f in ['config.json', 'model.safetensors', 'vocab.txt']):
            print("âŒ æ¨¡å‹ä¿å­˜ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ç£ç›˜ç©ºé—´æˆ–æƒé™")
            return None, None
    
    # åˆå§‹åŒ–RAGæ£€ç´¢å™¨
    docx_file = project_root / "input.docx"
    if not docx_file.exists():
        print(f"âŒ RAGæ–‡æ¡£ä¸å­˜åœ¨: {docx_file}")
        return None, None
        
    retrieve_answer = create_rag_retriever(str(docx_file))
    
    return classifier, retrieve_answer
    

@app.route('/api/chat', methods=['POST', 'OPTIONS'])
def handle_chat():
    if request.method == 'OPTIONS':
        # ç›´æ¥è¿”å› 200ï¼Œè®©æµè§ˆå™¨ç»§ç»­å‘é€ POST
        return jsonify({}), 200
    try:
        try:
            data = request.json
            print("è§£æçš„JSONæ•°æ®:", data)
        except Exception as e:
            print("JSONè§£æé”™è¯¯:", str(e))
            return jsonify({"error": "æ— æ•ˆçš„JSONæ ¼å¼"}), 400

        if data is None:
            # å°è¯•ä»¥è¡¨å•å½¢å¼è§£æï¼ˆä»¥é˜²å‰ç«¯å‘é€çš„æ˜¯è¡¨å•æ•°æ®ï¼‰
            form_data = request.form
            print("å°è¯•ä»¥è¡¨å•å½¢å¼è§£æ:", form_data)
            user_message = form_data.get('message', '')
            if not user_message:
                return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯"}), 400
        else:
            user_message = data.get('message', '')
            if not user_message:
                return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400
        
        ai_response = ""
        ai_response += f"æ‚¨åˆšæ‰è¯´çš„æ˜¯{user_message}\n"

        questions = [user_message]
        predictions = classifier.predict(questions)
        for q, pred in zip(questions, predictions):
                ai_response += f"é¢„æµ‹: {'éœ€è¦æ£€ç´¢' if pred == 1 else 'ç›´æ¥ç”Ÿæˆ'}\n"
                ai_response += "-"*50

        predictions2 = retrieve_answer(user_message)
        ai_response += f"{predictions2}"
        
        # è®°å½•å¯¹è¯å†å²
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        chat_history.append({
            "type": "user",
            "content": user_message,
            "timestamp": timestamp
        })
        chat_history.append({
            "type": "ai",
            "content": ai_response,
            "timestamp": timestamp
        })
        
        return jsonify({
            "response": ai_response,
            "timestamp": timestamp
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/upload', methods=['POST'])
def handle_upload():
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
    if 'file' not in request.files:
        return jsonify({"error": "æ²¡æœ‰æ–‡ä»¶"}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400
    
    if file:
        # ä¿å­˜æ–‡ä»¶
        filename = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        file.save(filename)
        
        # è®°å½•ä¸Šä¼ å†å²å¹¶è¿”å›å›ºå®šæ¶ˆæ¯
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        chat_history.append({
            "type": "user",
            "content": f"ä¸Šä¼ äº†æ–‡ä»¶ï¼š{file.filename}",
            "timestamp": timestamp
        })
        
        ai_response = f"æ–‡ä»¶ã€Œ{file.filename}ã€å·²æ¥æ”¶ï¼Œè¿™æ˜¯å›ºå®šçš„å¤„ç†ç»“æœ"
        chat_history.append({
            "type": "ai",
            "content": ai_response,
            "timestamp": timestamp
        })
        
        return jsonify({
            "response": ai_response,
            "filename": file.filename,
            "timestamp": timestamp
        })

@app.route('/api/history', methods=['GET'])
def get_history():
    """è·å–å¯¹è¯å†å²"""
    return jsonify({
        "history": chat_history
    })

@app.route('/api/history', methods=['DELETE'])
def clear_history():
    """æ¸…ç©ºå¯¹è¯å†å²"""
    global chat_history
    chat_history = []
    return jsonify({"message": "å†å²è®°å½•å·²æ¸…ç©º"})



if __name__ == '__main__':
    # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
    if not os.path.exists(UPLOAD_FOLDER):
        os.makedirs(UPLOAD_FOLDER)

    # åˆå§‹åŒ–æ¨¡å‹
    classifier, retrieve_answer = init_model()
    if classifier is None or retrieve_answer is None:
        print("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡")
        exit(1)

    app.run(debug=True, host='0.0.0.0', port=5000)
